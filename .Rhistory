best.accuracy <- accuracy
best.auc <- aucGBM
besttree <- t
bestdepth <- d
}
# if (best.auc < aucGBM) {
#   best.auc <- aucGBM
#   besttree <- t
#   bestdepth <- d
# }
}
best.accuracy
best.auc
besttree
bestdepth
for (t in c(50, 100, 150, 200)) {
for (d in c(1,3,5,7)) {
set.seed(32909225)
gbm_model <- gbm(Class ~ A01 + A23 + A22 + A18, data = scaled.train, distribution = "bernoulli", n.trees = t, interaction.depth = d)
gbm.preds <- predict(gbm_model, newdata = scaled.test, type = "response", n.trees = t)
gbm.pred <- prediction(gbm.preds, scaled.test$Class)
#get auc
aucGBM <- performance(gbm.pred, measure = "auc")@y.values[[1]]
predlbls <- ifelse(gbm.preds > 0.5, "Positive", "Negative")
cmGBM <- table(predlbls, scaled.test$Class)
accuracy <- sum(diag(cmGBM)) / sum(cmGBM)
if (best.accuracy < accuracy) {
best.accuracy <- accuracy
best.auc <- aucGBM
besttree <- t
bestdepth <- d
}
# if (best.auc < aucGBM) {
#   best.auc <- aucGBM
#   besttree <- t
#   bestdepth <- d
# }
}
}
best.accuracy
best.auc
besttree
bestdepth
#install.packages("gbm")
library(gbm)
#initial gbm model
set.seed(32909225)
gbm_model <- gbm(Class ~ A01 + A23 + A22 + A18, data = scaled.train, distribution = "bernoulli", n.trees = 100, interaction.depth = 4)
gbm.preds <- predict(gbm_model, newdata = scaled.test, type = "response", n.trees = 100)
gbm.pred <- prediction(gbm.preds, scaled.test$Class)
#get auc
aucGBM <- performance(gbm.pred, measure = "auc")@y.values[[1]]
aucGBM # 0.7817199
predlbls <- ifelse(gbm.preds > 0.5, "Positive", "Negative")
cmGBM <- table(predlbls, scaled.test$Class)
accuracy <- sum(diag(cmGBM)) / sum(cmGBM)
accuracy # 0.7478814
best.accuracy <- 0
best.auc <- 0
besttree <- 0
bestdepth <- 0
for (t in c(50, 100, 150, 200)) {
for (d in c(1,3,5,7)) {
set.seed(32909225)
gbm_model <- gbm(Class ~ A01 + A23 + A22 + A18, data = scaled.train, distribution = "bernoulli", n.trees = t, interaction.depth = d)
gbm.preds <- predict(gbm_model, newdata = scaled.test, type = "response", n.trees = t)
gbm.pred <- prediction(gbm.preds, scaled.test$Class)
#get auc
aucGBM <- performance(gbm.pred, measure = "auc")@y.values[[1]]
predlbls <- ifelse(gbm.preds > 0.5, "Positive", "Negative")
cmGBM <- table(predlbls, scaled.test$Class)
accuracy <- sum(diag(cmGBM)) / sum(cmGBM)
# if (best.accuracy < accuracy) {
#   best.accuracy <- accuracy
#   best.auc <- aucGBM
#   besttree <- t
#   bestdepth <- d
# }
if (best.auc < aucGBM) {
best.auc <- aucGBM
best.accuracy <- accuracy
besttree <- t
bestdepth <- d
}
}
}
best.accuracy
best.auc
besttree
bestdepth
best.accuracy <- 0
best.auc <- 0
besttree <- 0
bestdepth <- 0
for (t in c(50, 100, 150, 200)) {
for (d in c(1,3,5,7)) {
set.seed(32909225)
gbm_model <- gbm(Class ~ A01 + A23 + A22, data = scaled.train, distribution = "bernoulli", n.trees = t, interaction.depth = d)
gbm.preds <- predict(gbm_model, newdata = scaled.test, type = "response", n.trees = t)
gbm.pred <- prediction(gbm.preds, scaled.test$Class)
#get auc
aucGBM <- performance(gbm.pred, measure = "auc")@y.values[[1]]
predlbls <- ifelse(gbm.preds > 0.5, "Positive", "Negative")
cmGBM <- table(predlbls, scaled.test$Class)
accuracy <- sum(diag(cmGBM)) / sum(cmGBM)
if (best.accuracy < accuracy) {
best.accuracy <- accuracy
best.auc <- aucGBM
besttree <- t
bestdepth <- d
}
# if (best.auc < aucGBM) {
#   best.auc <- aucGBM
#   best.accuracy <- accuracy
#   besttree <- t
#   bestdepth <- d
# }
}
}
best.accuracy
best.auc
besttree
bestdepth
for (t in c(50, 100, 150, 200)) {
for (d in c(1,3,5,7)) {
set.seed(32909225)
gbm_model <- gbm(Class ~ A01 + A23 + A22, data = scaled.train, distribution = "bernoulli", n.trees = t, interaction.depth = d)
gbm.preds <- predict(gbm_model, newdata = scaled.test, type = "response", n.trees = t)
gbm.pred <- prediction(gbm.preds, scaled.test$Class)
#get auc
aucGBM <- performance(gbm.pred, measure = "auc")@y.values[[1]]
predlbls <- ifelse(gbm.preds > 0.5, "Positive", "Negative")
cmGBM <- table(predlbls, scaled.test$Class)
accuracy <- sum(diag(cmGBM)) / sum(cmGBM)
if (best.accuracy < accuracy) {
best.accuracy <- accuracy
best.auc <- aucGBM
besttree <- t
bestdepth <- d
}
# if (best.auc < aucGBM) {
#   best.auc <- aucGBM
#   best.accuracy <- accuracy
#   besttree <- t
#   bestdepth <- d
# }
}
}
best.accuracy
best.auc
besttree
bestdepth
best.accuracy <- 0
best.auc <- 0
besttree <- 0
bestdepth <- 0
for (t in c(50, 100, 150, 200)) {
for (d in c(1,3,5,7)) {
set.seed(32909225)
gbm_model <- gbm(Class ~ A01 + A23 , data = scaled.train, distribution = "bernoulli", n.trees = t, interaction.depth = d)
gbm.preds <- predict(gbm_model, newdata = scaled.test, type = "response", n.trees = t)
gbm.pred <- prediction(gbm.preds, scaled.test$Class)
#get auc
aucGBM <- performance(gbm.pred, measure = "auc")@y.values[[1]]
predlbls <- ifelse(gbm.preds > 0.5, "Positive", "Negative")
cmGBM <- table(predlbls, scaled.test$Class)
accuracy <- sum(diag(cmGBM)) / sum(cmGBM)
if (best.accuracy < accuracy) {
best.accuracy <- accuracy
best.auc <- aucGBM
besttree <- t
bestdepth <- d
}
# if (best.auc < aucGBM) {
#   best.auc <- aucGBM
#   best.accuracy <- accuracy
#   besttree <- t
#   bestdepth <- d
# }
}
}
best.accuracy
best.auc
besttree
bestdepth
# we have 2 parameters we can test interaction depth n trees
best.accuracy <- 0
best.auc <- 0
besttree <- 0
bestdepth <- 0
for (t in c(50, 100, 150, 200)) {
for (d in c(1,3,5,7)) {
set.seed(32909225)
gbm_model <- gbm(Class ~ A01 + A23  A22 + A18, data = scaled.train, distribution = "bernoulli", n.trees = t, interaction.depth = d)
# we have 2 parameters we can test interaction depth n trees
best.accuracy <- 0
best.auc <- 0
besttree <- 0
bestdepth <- 0
for (t in c(50, 100, 150, 200)) {
for (d in c(1,3,5,7)) {
set.seed(32909225)
gbm_model <- gbm(Class ~ A01 + A23 + A22 + A18, data = scaled.train, distribution = "bernoulli", n.trees = t, interaction.depth = d)
gbm.preds <- predict(gbm_model, newdata = scaled.test, type = "response", n.trees = t)
gbm.pred <- prediction(gbm.preds, scaled.test$Class)
#get auc
aucGBM <- performance(gbm.pred, measure = "auc")@y.values[[1]]
predlbls <- ifelse(gbm.preds > 0.5, "Positive", "Negative")
cmGBM <- table(predlbls, scaled.test$Class)
accuracy <- sum(diag(cmGBM)) / sum(cmGBM)
if (best.accuracy < accuracy) {
best.accuracy <- accuracy
best.auc <- aucGBM
besttree <- t
bestdepth <- d
}
# if (best.auc < aucGBM) {
#   best.auc <- aucGBM
#   best.accuracy <- accuracy
#   besttree <- t
#   bestdepth <- d
# }
}
}
best.accuracy
best.auc
besttree
bestdepth
performance.metrics
#initial gbm model
set.seed(32909225)
gbm_model <- gbm(Class ~ A01 + A23 + A22 + A18, data = scaled.train, distribution = "bernoulli", n.trees = 50, interaction.depth = 1)
gbm.preds <- predict(gbm_model, newdata = scaled.test, type = "response", n.trees = 100)
gbm.pred <- prediction(gbm.preds, scaled.test$Class)
#get auc
aucGBM <- performance(gbm.pred, measure = "auc")@y.values[[1]]
aucGBM # 0.7817199
predlbls <- ifelse(gbm.preds > 0.5, "Positive", "Negative")
cmGBM <- table(predlbls, scaled.test$Class)
accuracy <- sum(diag(cmGBM)) / sum(cmGBM)
accuracy
set.seed(32909225)
gbm_model <- gbm(Class ~ A01 + A23 + A22 + A18, data = scaled.train, distribution = "adaboost", n.trees = 100, interaction.depth = 4)
gbm.preds <- predict(gbm_model, newdata = scaled.test, type = "response", n.trees = 100)
gbm.pred <- prediction(gbm.preds, scaled.test$Class)
#get auc
aucGBM <- performance(gbm.pred, measure = "auc")@y.values[[1]]
aucGBM # 0.7817199
predlbls <- ifelse(gbm.preds > 0.5, "Positive", "Negative")
cmGBM <- table(predlbls, scaled.test$Class)
accuracy <- sum(diag(cmGBM)) / sum(cmGBM)
accuracy # 0.7478814
set.seed(32909225)
gbm_model <- gbm(Class ~ A01 + A23 + A22 + A18, data = scaled.train, distribution = "adaboost", n.trees = 50, interaction.depth = 1)
gbm.preds <- predict(gbm_model, newdata = scaled.test, type = "response", n.trees = 100)
gbm.pred <- prediction(gbm.preds, scaled.test$Class)
#get auc
aucGBM <- performance(gbm.pred, measure = "auc")@y.values[[1]]
aucGBM # 0.7817199
predlbls <- ifelse(gbm.preds > 0.5, "Positive", "Negative")
cmGBM <- table(predlbls, scaled.test$Class)
accuracy <- sum(diag(cmGBM)) / sum(cmGBM)
accuracy # 0.7478814
# we have 2 parameters we can test interaction depth n trees
best.accuracy <- 0
best.auc <- 0
besttree <- 0
bestdepth <- 0
for (t in c(50, 100, 150, 200)) {
for (d in c(1,3,5,7)) {
set.seed(32909225)
gbm_model <- gbm(Class ~ A01 + A23 + A22 + A18, data = scaled.train, distribution = "adaboost", n.trees = t, interaction.depth = d)
gbm.preds <- predict(gbm_model, newdata = scaled.test, type = "response", n.trees = t)
gbm.pred <- prediction(gbm.preds, scaled.test$Class)
#get auc
aucGBM <- performance(gbm.pred, measure = "auc")@y.values[[1]]
predlbls <- ifelse(gbm.preds > 0.5, "Positive", "Negative")
cmGBM <- table(predlbls, scaled.test$Class)
accuracy <- sum(diag(cmGBM)) / sum(cmGBM)
if (best.accuracy < accuracy) {
best.accuracy <- accuracy
best.auc <- aucGBM
besttree <- t
bestdepth <- d
}
}
}
best.accuracy
best.auc
besttree
bestdepth
# we have 2 parameters we can test interaction depth n trees
best.accuracy <- 0
best.auc <- 0
besttree <- 0
bestdepth <- 0
for (t in c(50, 100, 150, 200)) {
for (d in c(1,3,5,7)) {
set.seed(32909225)
gbm_model <- gbm(Class ~ A01 + A23 + A22 + A18, data = scaled.train, distribution = "bernoulli", n.trees = t, interaction.depth = d)
gbm.preds <- predict(gbm_model, newdata = scaled.test, type = "response", n.trees = t)
gbm.pred <- prediction(gbm.preds, scaled.test$Class)
#get auc
aucGBM <- performance(gbm.pred, measure = "auc")@y.values[[1]]
predlbls <- ifelse(gbm.preds > 0.5, "Positive", "Negative")
cmGBM <- table(predlbls, scaled.test$Class)
accuracy <- sum(diag(cmGBM)) / sum(cmGBM)
if (best.accuracy < accuracy) {
best.accuracy <- accuracy
best.auc <- aucGBM
besttree <- t
bestdepth <- d
}
}
}
best.accuracy
best.auc
besttree
bestdepth
set.seed(32909225)
gbm_model <- gbm(Class ~ A01 + A23 + A22 + A18, data = scaled.train, distribution = "bernoulli", n.trees = 50, interaction.depth = 1)
gbm.preds <- predict(gbm_model, newdata = scaled.test, type = "response", n.trees = 100)
gbm.pred <- prediction(gbm.preds, scaled.test$Class)
#get auc
aucGBM <- performance(gbm.pred, measure = "auc")@y.values[[1]]
aucGBM # 0.7817199
predlbls <- ifelse(gbm.preds > 0.5, "Positive", "Negative")
cmGBM <- table(predlbls, scaled.test$Class)
cmGBm
set.seed(32909225)
gbm_model <- gbm(Class ~ A01 + A23 + A22 + A18, data = scaled.train, distribution = "bernoulli", n.trees = 50, interaction.depth = 1)
gbm.preds <- predict(gbm_model, newdata = scaled.test, type = "response", n.trees = 100)
gbm.pred <- prediction(gbm.preds, scaled.test$Class)
#get auc
aucGBM <- performance(gbm.pred, measure = "auc")@y.values[[1]]
aucGBM # 0.7817199
predlbls <- ifelse(gbm.preds > 0.5, "Positive", "Negative")
cmGBM <- table(predlbls, scaled.test$Class)
cmGBM
accuracy <- sum(diag(cmGBM)) / sum(cmGBM)
accuracy # 0.7478814
cmGBM
accuracy <- sum(diag(cmGBM)) / sum(cmGBM)
accuracy # 0.7478814
aucGBM
#initial gbm model
set.seed(32909225)
gbm_model <- gbm(Class ~ A01 + A23 + A22 + A18, data = scaled.train, distribution = "bernoulli", n.trees = 100, interaction.depth = 4)
gbm.preds <- predict(gbm_model, newdata = scaled.test, type = "response", n.trees = 100)
gbm.pred <- prediction(gbm.preds, scaled.test$Class)
#get auc
aucGBM <- performance(gbm.pred, measure = "auc")@y.values[[1]]
aucGBM # 0.7817199
predlbls <- ifelse(gbm.preds > 0.5, "Positive", "Negative")
cmGBM <- table(predlbls, scaled.test$Class)
cmGBM
accuracy <- sum(diag(cmGBM)) / sum(cmGBM)
accuracy # 0.7478814
aucGBM
set.seed(32909225)
gbm_model <- gbm(Class ~ A01 + A23 + A22 + A18, data = scaled.train, distribution = "bernoulli", n.trees = 100, interaction.depth = 4)
gbm.preds <- predict(gbm_model, newdata = scaled.test, type = "response", n.trees = 100)
gbm.pred <- prediction(gbm.preds, scaled.test$Class)
#get auc
aucGBM <- performance(gbm.pred, measure = "auc")@y.values[[1]]
aucGBM # 0.7817199
predlbls <- ifelse(gbm.preds > 0.5, "Phishhing", "Legitimate")
cmGBM <- table(predlbls, scaled.test$Class)
cmGBM
accuracy <- sum(diag(cmGBM)) / sum(cmGBM)
accuracy # 0.7478814
aucGBM
set.seed(32909225)
gbm_model <- gbm(Class ~ A01 + A23 + A22 + A18, data = scaled.train, distribution = "bernoulli", n.trees = 100, interaction.depth = 4)
gbm.preds <- predict(gbm_model, newdata = scaled.test, type = "response", n.trees = 100)
gbm.pred <- prediction(gbm.preds, scaled.test$Class)
#get auc
aucGBM <- performance(gbm.pred, measure = "auc")@y.values[[1]]
aucGBM # 0.7817199
predlbls <- ifelse(gbm.preds > 0.6, "Phishing", "Legitimate")
cmGBM <- table(predlbls, scaled.test$Class)
cmGBM
accuracy <- sum(diag(cmGBM)) / sum(cmGBM)
accuracy # 0.7478814
aucGBM
set.seed(32909225)
gbm_model <- gbm(Class ~ A01 + A23 + A22 + A18, data = scaled.train, distribution = "bernoulli", n.trees = 100, interaction.depth = 4)
gbm.preds <- predict(gbm_model, newdata = scaled.test, type = "response", n.trees = 100)
gbm.pred <- prediction(gbm.preds, scaled.test$Class)
#get auc
aucGBM <- performance(gbm.pred, measure = "auc")@y.values[[1]]
aucGBM # 0.7817199
predlbls <- ifelse(gbm.preds > 0.8, "Phishing", "Legitimate")
cmGBM <- table(predlbls, scaled.test$Class)
cmGBM
accuracy <- sum(diag(cmGBM)) / sum(cmGBM)
accuracy # 0.7478814
aucGBM
set.seed(32909225)
gbm_model <- gbm(Class ~ A01 + A23 + A22 + A18, data = scaled.train, distribution = "bernoulli", n.trees = 100, interaction.depth = 4)
gbm.preds <- predict(gbm_model, newdata = scaled.test, type = "response", n.trees = 100)
gbm.pred <- prediction(gbm.preds, scaled.test$Class)
#get auc
aucGBM <- performance(gbm.pred, measure = "auc")@y.values[[1]]
aucGBM # 0.7817199
predlbls <- ifelse(gbm.preds > 0.6, "Phishing", "Legitimate")
cmGBM <- table(predlbls, scaled.test$Class)
cmGBM
accuracy <- sum(diag(cmGBM)) / sum(cmGBM)
accuracy # 0.7478814
aucGBM
predlbls <- ifelse(gbm.preds > 0.5, "Phishing", "Legitimate")
cmGBM <- table(predlbls, scaled.test$Class)
cmGBM
accuracy <- sum(diag(cmGBM)) / sum(cmGBM)
accuracy # 0.7478814
aucGBM
# we have 2 parameters we can test interaction depth n trees
best.accuracy <- 0
best.auc <- 0
besttree <- 0
bestdepth <- 0
for (t in c(50, 100, 150, 200, 250, 300)) {
for (d in c(1,3,5,7, 9, 10,12)) {
set.seed(32909225)
gbm_model <- gbm(Class ~ A01 + A23 + A22 + A18, data = scaled.train, distribution = "bernoulli", n.trees = t, interaction.depth = d)
gbm.preds <- predict(gbm_model, newdata = scaled.test, type = "response", n.trees = t)
gbm.pred <- prediction(gbm.preds, scaled.test$Class)
#get auc
aucGBM <- performance(gbm.pred, measure = "auc")@y.values[[1]]
predlbls <- ifelse(gbm.preds > 0.5, "Positive", "Negative")
cmGBM <- table(predlbls, scaled.test$Class)
accuracy <- sum(diag(cmGBM)) / sum(cmGBM)
if (best.accuracy < accuracy) {
best.accuracy <- accuracy
best.auc <- aucGBM
besttree <- t
bestdepth <- d
}
}
}
best.accuracy # 0.7817797
best.auc # 0.7787982
besttree # 50
bestdepth # 1
# we have 2 parameters we can test interaction depth n trees
best.accuracy <- 0
best.auc <- 0
besttree <- 0
bestdepth <- 0
for (t in c(50, 100, 150, 200, 250, 300)) {
for (d in c(1,3,5,7, 9, 10,12)) {
set.seed(32909225)
gbm_model <- gbm(Class ~ A01 + A23 + A22 + A18, data = scaled.train, distribution = "bernoulli", n.trees = t, interaction.depth = d)
gbm.preds <- predict(gbm_model, newdata = scaled.test, type = "response", n.trees = t)
gbm.pred <- prediction(gbm.preds, scaled.test$Class)
#get auc
aucGBM <- performance(gbm.pred, measure = "auc")@y.values[[1]]
predlbls <- ifelse(gbm.preds > 0.5, "Positive", "Negative")
cmGBM <- table(predlbls, scaled.test$Class)
accuracy <- sum(diag(cmGBM)) / sum(cmGBM)
# if (best.accuracy < accuracy) {
#   best.accuracy <- accuracy
#   best.auc <- aucGBM
#   besttree <- t
#   bestdepth <- d
# }
if (best.auc < aucGBM) {
best.accuracy <- accuracy
best.auc <- aucGBM
besttree <- t
bestdepth <- d
}
}
}
best.accuracy # 0.7817797
best.auc # 0.7787982
besttree # 50
bestdepth # 1
rm(list = ls())
install.packages("tm") # requires R 3.3.1 or later
install.packages("slam")
install.packages("SnowballC")
library(slam) # for matrices and arrays
library(tm)
library(SnowballC)
getwd()
setwd("C:/Users/Nathan/Documents/FIT3152/Assignment 3")
cname = file.path(".", "CorpusAbstracts", "txt")
dir(cname)
docs = Corpus(DirSource((cname)))
summary(docs)
# Load necessary library
library(dplyr)
# Set the file path for the input CSV
input_file <- "train_service_passenger_counts_fy_2023-2024.csv"
# Load the data from the CSV file
data <- read.csv(input_file)
wd()
getwd()
cd("C:\Users\Nathan\Documents\FIT3179HW9\FIT3179HW9")
cd("C:/Users/Nathan/Documents/FIT3179HW9/FIT3179HW9")
setwd("C:/Users/Nathan/Documents/FIT3179HW9/FIT3179HW9")
# Set the file path for the output CSV
output_file <- "train_service_passenger_counts_sampled.csv"
# Load the data from the CSV file
data <- read.csv(input_file)
# Randomly sample 500,000 rows
sampled_data <- data %>%
sample_n(500000)
# Save the sampled data to a new CSV file
write.csv(sampled_data, output_file, row.names = FALSE)
